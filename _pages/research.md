---
layout: archive
title: "Research"
permalink: /publications/
author_profile: true
---

## Lookit: bringing developmental studies home

<img src="../../files/img/computerbaby.jpg" alt="toddler on the computer" class="research_thumbnail" />

The Lookit website allows families to participate in developmental studies online using their own computer and webcam. Why put experiments online? We're looking to:

- work with "real" (more representative) families - not just the folks who live near developmental labs and can come in on weekdays

- enable more people to do rigorous developmental research - especially people with ideas that directly benefit kids and families, like early childhood educators

- allow researchers to collect larger sample sizes when needed - for instance, to measure graded effects instead of just comparing A and B, or to make studies more robust and reproducible

- improve retention in longitudinal studies, and make it possible to try out the sorts of intensive interventions that might really make a difference

- observe more natural behavior in the home, rather than the "going on a special trip" behavior we see in the lab

- accelerate work with special populations (for example, kids with rare developmental disorders, scattered across the world)

- make it easier to share complete protocols and materials so that other scientists can understand and build on a finding

Learn more or participate with your kids at [Lookit](https://lookit.mit.edu), view the source code on [github](https://github.com/lookit/) (lookit, experimenter, and                                      exp-addons repos), or connect with us on [Facebook](https://www.facebook.com/lookit.mit.edu) or [Instagram](https://www.instagram.com/babiesoflookit/). To stay up-to-date on 
progress on the platform, you can join the [lookit-research mailing list](http://mailman.mit.edu/mailman/listinfo/lookit-research).

### Current & planned projects

- Intuitive physics & individual differences in preferential looking (with Liz Spelke, Melissa Kline - [participate: "Your baby, the physicist"](https://lookit.mit.edu/studies/cfddb63f-12e9-4e62-abd1-47534d6c4dd2/))

- Shape sensitivity in 7-month-olds (with Molly Dillon, Liz Spelke - data collection 
recently completed)

- Preschoolers' politeness judgments (with Erica Yoon, Mike Frank - data collection recently completed)

- Preschoolers' expectations of ingroup/outgroup behavior (with Lisa Chalik, Yarrow Dunham - [participate: "Flurps and Zazzes"](https://lookit.mit.edu/studies/1e9157cd-b898-4098-9429-a599720d0c0a/))

- Neonatal imitation (with Laurie Bayet)

- Approximate number system acuity in deaf and hard-of-hearing children (with Stacee Santos)

- Literacy assessment and intervention (with Reaching Every Reader, Harvard/MIT)

- Intermodal speech matching (with Halie Olson, Rebecca Saxe)

- Baby laughter (with Caspar Addyman)

### Automated gaze coding for developmental research

The next bottleneck for running infant studies at scale is coding the data: a human needs to watch the collected video, generally at 1/10 - 1/2 speed depending on the desired granularity, to record where the infant is looking each frame. Algorithms for automated gaze coding from natural-light video (as opposed to measurements from specialized eyetracking hardware) are finally reaching the point where they could be productively adapted for developmental data collection. (Take a look at some examples of running OpenFace on webcam video of babies: [1](https://drive.google.com/open?id=1pkmLJ_ICEcuShy9SNTWguGRVRhTITdJp), [2](https://drive.google.com/open?id=1o5WKNCjYE58x6FcQ0NmK6B65TNZk7ro4).)
To get involved in efforts in this direction, you can join the [baby-gaze-coding mailing list](http://mailman.mit.edu/mailman/listinfo/baby-gaze-coding). 

## What's it like to be a baby?

<img src="../../files/img/newborn_remy.jpg" alt="newborn baby" class="research_thumbnail" />

My more empirical work has focused on early conscious experience: for instance, how infants merge multiple representations of the same concept; understand the passage of time; and distinguish among imagery, memory, and  perception.
                    
## Papers

Scott, K. M. Split-brain babies? Differences in representation of bilaterally and unilaterally presented visual concepts in infancy. (In press.) Frontiers in Psychology.  (<a href="https://psyarxiv.com/mnfx8/">preprint</a>, <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02758/abstract"> abstract </a>).

Scott, K. M. and Kline, M. Enabling confirmatory secondary data analysis by logging data 'checkout'. (In press.) Advances in Methods and Practices in Psychological Science. (<a href="https://psyarxiv.com/87wjc/">preprint</a>)

Chouinard, B., Scott, K., and Cusack, R. (2019). Using automatic face analysis to score infant behaviour from video collected online. Infant Behavior and Development 54:1-12. https://doi.org/10.1016/j.infbeh.2018.11.004. (<a href="https://www.sciencedirect.com/science/article/pii/S0163638318301395">full text</a>)

Scott, K. M. and Schulz, L. E. (2017). Lookit (part 1): a new online platform for developmental research. Open Mind 1(1):4-14. (<a href="https://www.mitpressjournals.org/doi/full/10.1162/OPMI_a_00002">full text</a>)

Scott, K. M., Chu, J., and Schulz, L. E. (2017). Lookit (part 2): Assessing the viability of online developmental research, results from three case studies. Open Mind 1(1):15-29.
(<a href="https://www.mitpressjournals.org/doi/abs/10.1162/OPMI_a_00001">full text</a>)

Scott, K.M. & Schulz, L.E. (2014, July). Interhemispheric integration of visual concepts in infancy. Paper presented at the annual meeting of the Cognitive Science Society, Quebec City, Canada. (<a href="https://mindmodeling.org/cogsci2014/papers/245/paper245.pdf">pdf</a>)

Scott, K. M., Du, J., Lester, H. A., &amp; Masmanidis, S. C. (2012).  Variability of acute extracellular action potential measurements with  multisite silicon probes. <em>Journal of Neuroscience Methods</em> <b>211</b>(1), 22-30. 
(<a href="../../files/slides/Scott-JNeurosciMeth-2012.pdf">pdf</a>)
                                               
Moss, F. J., Imoukhuede, P. I., Scott, K., Hu, J., Jankowsky, J. L., Quick, M. W., &amp; Lester,  H. A. (2009). GABA transporter function, oligomerization state, and  anchoring: correlates with subcellularly resolved FRET. <em>The Journal of general physiology</em>, <em>134</em>(6), 489-521. (<a href="http://jgp.rupress.org/content/134/6/489.long">full text</a>)

## Student papers

PhD thesis: Online data collection for developmental research.  (<a href="https://thesiscommons.org/qjs9y">Thesis commons</a>)

Undergraduate SURF paper: Effects of nicotine on neuronal firing patterns in human subthalamic nucleus (<a href="../../files/slides/draft.pdf">pdf</a>, <a href="../../files/slides/SURFtalkPerpallFinal.pdf">slides</a>)

Undergraduate SURF paper: Detecting multiple oligomerization states by multidimensional analysis of FRET images (<a              href="../../files/slides/KSFinalReportSURF09.pdf">pdf</a>, <a href="../../files/slides/KSperpallSemi0910.pdf">slides</a>)

## Media coverage

[Society for Science and the Public: Babies, parenthood, and science (June 2018)](https://student.societyforscience.org/blog/doing-science/babies-parenthood-and-science)

[MITili blog: Q&A with MIT's Kim Scott in the Early Childhood Cognition Lab (December 2017)](http://mitili.mit.edu/news/qa-mits-kim-scott-early-childhood-cognition-lab)

[MIT Campaign: Better data on how babies learn (November 2016)](https://betterworld.mit.edu/better-data-babies-learn/)

[Pacific Standard: The 30 top thinkers under 30 (March 2016)](https://psmag.com/social-justice/the-30-top-thinkers-under-30-kim-scott)

[Science News, Growth Curve: Your baby can watch movies for science (June 2014)](https://www.sciencenews.org/blog/growth-curve/your-baby-can-watch-movies-science)

[Parents Magazine: Parents Perspective (June 2014)](https://www.parents.com/parents-magazine/parents-perspective/participate-in-mit-research-from-your-couch/)

[MIT News: MIT launches online lab to study early childhood learning (June 2014)](http://news.mit.edu/2014/mit-launches-online-lab-early-childhood-learning-lookit)

[Boston Magazine: MIT launches a new online lab (June 2014)](http://www.bostonmagazine.com/health/blog/2014/06/19/new-mit-lab/)


<!---
{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}
-->
